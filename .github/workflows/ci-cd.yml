name: CI/CD for Airflow on GCP

on:
  push:
    branches:
      - main   # triggers when code is pushed to main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup SSH key
        run: |
          SSH_DIR="$HOME/.ssh"
          mkdir -p "$SSH_DIR"
          chmod 700 "$SSH_DIR"

          # Use printf to preserve newlines in the private key
          printf "%s\n" "${{ secrets.GCP_SSH_KEY }}" > "$SSH_DIR/id_rsa"
          chmod 600 "$SSH_DIR/id_rsa"

          ssh-keyscan -H "${{ secrets.GCP_VM_HOST }}" >> "$SSH_DIR/known_hosts"

      - name: Deploy code to GCP VM
        run: |
          ssh -i ~/.ssh/id_rsa ${{ secrets.GCP_VM_USER }}@${{ secrets.GCP_VM_HOST }} << 'EOF'
            # Set project folder
            PROJ_DIR=/home/learning_subscriptions25/cloud-airflow-data-pipeline
            AIRFLOW_DIR=/home/learning_subscriptions25/airflow

            # Create parent folder if it doesn't exist
            mkdir -p "$(dirname "$PROJ_DIR")"

            # Clone repo if folder doesn't exist, otherwise pull updates
            if [ ! -d "$PROJ_DIR/.git" ]; then
              git clone https://github.com/Hashem-Qaryouti/cloud-airflow-data-pipeline.git
            else
              cd "$PROJ_DIR"
              git pull origin main
            fi
            cp -r $PROJ_DIR/dags/* $AIRFLOW_DIR/dags/
          EOF
